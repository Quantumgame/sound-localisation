{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Binaural sound localisation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook fits machine learning models on simulated binaural audio. The source audio file contains music notes using a sawtooth wave, white noise, as well as, 10 seconds of speaking from a variety of people (both male and female, young and old)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from brian.globalprefs import *\n",
      "import pygame\n",
      "from brian import *\n",
      "from brian.hears import *\n",
      "set_global_preferences(useweave=True, brianhears_usegpu = True, openmp = True, magic_useframes = False)\n",
      "from sklearn import svm\n",
      "from sklearn import cross_validation\n",
      "import time\n",
      "from StringIO import StringIO\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.cross_validation import cross_val_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This code block sets up the variables and helper functions. For the purposes of these experiments, the audio file is split into half-second intervals on which the filers are run, and then the filtered audio is averaged over 1050 sample (23  millisecond) blocks. \n",
      "\n",
      "The filters are a Gammatone filter bank (essentially a series of bandpass filter over a frequency range that roughly mimics the response of a human cochlea) of 40 bands over the 150Hz to 5000 Hz range.\n",
      "\n",
      "The simulated binaural response uses the IRCAM Listen database of head related implse responses to simulate the head realted transfer function associated with 187 locations in a room. This results in interaural intensity and time differences, as well as appropriate notches in the frequency response. The differences are asymmetrical between the two channels, which allows us to learn features associated with different source locations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sampletime = 0.5\n",
      "averaging = 1050   # needs to be a factor of 0.5*44100 = 22050\n",
      "samples = int(sampletime * 44100)\n",
      "\n",
      "n_filters = 40\n",
      "hrtfdb = IRCAM_LISTEN('ICAM/')\n",
      "subject = 1002\n",
      "hrtfset = hrtfdb.load_subject(subject)\n",
      "def colave(inpt, ncol):\n",
      "    shp = list(inpt.shape)\n",
      "    return reshape(mean(reshape(inpt, [inpt.size/ncol,ncol]),axis =1), [shp[0],shp[1]/ncol])\n",
      "\n",
      "def rowave(inpt, nrow):\n",
      "    shp = list(inpt.shape)\n",
      "    return reshape(mean(reshape(inpt.T, [inpt.size/nrow,nrow]),axis =1).T, [shp[1],shp[0]/nrow]).T\n",
      "\n",
      "def preprocess(x, samples, num_indices, n_filters, averaging):\n",
      "    a = reshape(x, [samples*num_indices,2*n_filters])\n",
      "    return rowave(a,averaging)\n",
      "\n",
      "n = 24\n",
      "num_indices = hrtfset.num_indices\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This code block applies the Gammatone filter bank to the recorded audio and does the averaging. It uses code from the Brian neural simulator example code as a starting point (See http://www.briansimulator.org/docs/examples-hears_sound_localisation_model.html). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "xave = None\n",
      "yave = None\n",
      "\n",
      "for i in range(0, n):\n",
      "    starttime = time.time()\n",
      "    offset = i*44100\n",
      "    # This gives the number of spatial locations in the set of HRTFs\n",
      "    num_indices = hrtfset.num_indices\n",
      "    # A sound to test the model with\n",
      "    #sound = Sound.whitenoise(500*ms)\n",
      "    sound = Sound('sounds/playback Playback.wav').left[offset:(offset+samples)]\n",
      "    # We apply the chosen HRTF to the sound, the output has 2 channels\n",
      "    hrtf_fb = hrtfset.filterbank(sound)\n",
      "    # We swap these channels (equivalent to swapping the channels in the\n",
      "    # subsequent filters, but simpler to do it with the inputs)\n",
      "    swapped_channels = RestructureFilterbank(hrtf_fb, indexmapping=[1, 0])\n",
      "    # Now we apply all of the possible pairs of HRTFs in the set to these\n",
      "    # swapped channels, which means repeating them num_indices times first\n",
      "    hrtfset_fb = hrtfset.filterbank(Repeat(swapped_channels, num_indices))\n",
      "    # Now we apply cochlear filtering (logically, this comes before the HRTF\n",
      "    # filtering, but since convolution is commutative it is more efficient to\n",
      "    # do the cochlear filtering afterwards\n",
      "    cfmin, cfmax, cfN = 150*Hz, 5*kHz, n_filters\n",
      "    cf = erbspace(cfmin, cfmax, cfN)\n",
      "    # We repeat each of the HRTFSet filterbank channels cfN times, so that\n",
      "    # for each location we will apply each possible cochlear frequency\n",
      "    gfb = Gammatone(Repeat(hrtfset_fb, cfN),\n",
      "                    tile(cf, hrtfset_fb.nchannels))\n",
      "    # Half wave rectification and compression\n",
      "    cochlea = FunctionFilterbank(gfb, lambda x:15*clip(x, 0, Inf)**(1.0/3.0))\n",
      "    cochleaout = cochlea.process()\n",
      "    \n",
      "    x = reshape(cochleaout, [samples*num_indices,2*n_filters])\n",
      "    if xave == None:\n",
      "        xave = rowave(x,averaging) \n",
      "        yave = repeat(range(0,num_indices),samples/averaging)\n",
      "    else:\n",
      "        xave = vstack((xave, rowave(x,averaging)))\n",
      "        yave = hstack((yave, repeat(range(0,num_indices),samples/averaging)))\n",
      "        \n",
      "    endtime = time.time()\n",
      "    print(\"Completed: %0.2f percent\" % ((i+1.0)/n*100))\n",
      "    print(\"Elapsed: %0.2f seconds. Est remaining time: %0.2f minutes\" % ((endtime - starttime),(endtime - starttime)*(n-i) / 60))\n",
      "    savetxt('xave1.csv',xave,delimiter=\",\")\n",
      "    savetxt('yave.csv',yave,delimiter=\",\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Completed: 4.17 percent\n",
        "Elapsed: 122.75 seconds. Est remaining time: 49.10 minutes\n",
        "Completed: 8.33 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 93.90 seconds. Est remaining time: 35.99 minutes\n",
        "Completed: 12.50 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 96.91 seconds. Est remaining time: 35.53 minutes\n",
        "Completed: 16.67 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 97.13 seconds. Est remaining time: 33.99 minutes\n",
        "Completed: 20.83 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 110.89 seconds. Est remaining time: 36.96 minutes\n",
        "Completed: 25.00 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 121.44 seconds. Est remaining time: 38.46 minutes\n",
        "Completed: 29.17 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 124.16 seconds. Est remaining time: 37.25 minutes\n",
        "Completed: 33.33 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 120.69 seconds. Est remaining time: 34.20 minutes\n",
        "Completed: 37.50 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 87.22 seconds. Est remaining time: 23.26 minutes\n",
        "Completed: 41.67 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 121.90 seconds. Est remaining time: 30.47 minutes\n",
        "Completed: 45.83 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 100.96 seconds. Est remaining time: 23.56 minutes\n",
        "Completed: 50.00 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 127.73 seconds. Est remaining time: 27.67 minutes\n",
        "Completed: 54.17 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 134.34 seconds. Est remaining time: 26.87 minutes\n",
        "Completed: 58.33 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 125.69 seconds. Est remaining time: 23.04 minutes\n",
        "Completed: 62.50 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 107.04 seconds. Est remaining time: 17.84 minutes\n",
        "Completed: 66.67 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 121.59 seconds. Est remaining time: 18.24 minutes\n",
        "Completed: 70.83 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 109.55 seconds. Est remaining time: 14.61 minutes\n",
        "Completed: 75.00 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 119.65 seconds. Est remaining time: 13.96 minutes\n",
        "Completed: 79.17 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 112.99 seconds. Est remaining time: 11.30 minutes\n",
        "Completed: 83.33 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 123.94 seconds. Est remaining time: 10.33 minutes\n",
        "Completed: 87.50 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 114.40 seconds. Est remaining time: 7.63 minutes\n",
        "Completed: 91.67 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 126.44 seconds. Est remaining time: 6.32 minutes\n",
        "Completed: 95.83 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 113.65 seconds. Est remaining time: 3.79 minutes\n",
        "Completed: 100.00 percent"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Elapsed: 115.17 seconds. Est remaining time: 1.92 minutes\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xave = genfromtxt('xave.csv', delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "yave = repeat(range(0,num_indices),samples/averaging)\n",
      "y = yave\n",
      "for i in range(0,23):\n",
      "    y = hstack((y, yave))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(659736, 80)\n",
        "(659736,)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print xave.shape\n",
      "print yave.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(94248, 80)\n",
        "(94248,)\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Machine Learning approach"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The models below are primarily to test the applicability of learning algorithms to this data. There is no feature engineering (importantly, I have not yet implemented a method to explicitly detect level differences or time differences). \n",
      "\n",
      "Their accuracy is evaluated as a classification problem rather than a measurement problem: so, for example, if the true location has an azimuth of 30 degrees and elevation of 45 degrees, and the learning algorithm outputs another class (say 35 , 45) it will be marked as incorrect. Ultimately, this problem will be convered into a regression problem (estimating the source elevation and azimuth), but the multiclass classification approach provides an easy metric to test the applicability of models."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### SVM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = 10000\n",
      "b = 10000\n",
      "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(xave, yave, test_size=0.4, random_state=0)\n",
      "clf = svm.LinearSVC(verbose = True)\n",
      "scores = cross_validation.cross_val_score(clf, xave[a:a+b], yave[a:a+b], cv=4, verbose=True)\n",
      "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
      "#clf.fit(X_train, y_train)\n",
      "#clf.score(X_test, y_test) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:  1.8min\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 0.79 (+/- 0.00)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  7.7min finished\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Random Forest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "clf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=1, random_state=0, n_jobs=8)\n",
      "scores = cross_val_score(clf, xave, yave)\n",
      "scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "0.77015957898310849"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Extra Randomised Trees"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "clf_extra = ExtraTreesClassifier(n_estimators=150, max_depth=None,min_samples_split=1, random_state=0, n_jobs=8)\n",
      "scores_extra = cross_val_score(clf_extra, xave, yave)\n",
      "scores_extra.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'cross_val_score' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-a6c095cc735e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf_extra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mscores_extra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_extra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mscores_extra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "\n",
      "clf_ada = AdaBoostClassifier(n_estimators=100)\n",
      "scores_ada = cross_val_score(clf_ada, xave, yave)\n",
      "scores_ada.mean()  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "0.010769459298871064"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The 85% cross-validation accuracy achieved by the extra randomised trees model is very encouraging, especially given that a small error in estimation will result in incorrect classification. More advanced methods that take into account the recurrect nature of the data (e.g. recurrect nets) may allow for further improved results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}